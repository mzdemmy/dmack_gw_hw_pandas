{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Analysis\n",
    "_**HARD: This is a curveball assignment. Plus, this is Python without Pandas.**_\n",
    "\n",
    "#### The objective of this assignment is for you to explain what is happening in each cell in clear, understandable language. \n",
    "\n",
    "#### _There is no need to code._ The code is there for you, and it already runs. Your task is only to explain what each line in each cell does.\n",
    "\n",
    "#### The placeholder cells should describe what happens in the cell below it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below imports `os` as a dependency because the `os.path.join` function. Also, the `string` dependency is needed because later in the script, `string.punctuation` will be used to detect and remove punctuation symbols. Explain what the line `from collection import Counter` does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below names the the path string (directory location) of the input/source file. Next two collections (sets) are defined as variable constants (indicated by all caps) meaning the set values cannot be changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "resume_path = os.path.join(\".\", 'resume.md')\n",
    "\n",
    "# Skills to match\n",
    "REQUIRED_SKILLS = {\"excel\", \"python\", \"mysql\", \"statistics\"}\n",
    "DESIRED_SKILLS = {\"r\", \"git\", \"html\", \"css\", \"leaflet\", \"modeling\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below calls a function that defines a local path to read and reformat a file into a list.  The .lower changes the file content to lower case. The .split separates content strings into rows (lists) and since a separater is not defined, whitespace will be used as the default.  by the hard return in the file . The return functions returns the lines of text that will be read in this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "    # Helper function to read a file and return the data.\n",
    "    with open(filepath, \"r\") as resume_file_handler:\n",
    "        resume_contents = resume_file_handler.read()\n",
    "        resume_contents = resume_contents.lower()\n",
    "        resume_tokens = resume_contents.split()\n",
    "        return resume_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below loads the source file data reformatted into a list by the load_file into a new variable named word_list.  \"word_list\" becomes the list of resume text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the text for a Resume\n",
    "word_list = load_file(resume_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below reads through each line of the list data and returns unique objects or strings into a set (an unordered collection of items).  A punctuation set is also created and is later used to remove matches from the \"resume\" set with the line \"resume = resume - punctuation\". (Subtracting \"punctuation\" from \"resume\" removes any matches (punctuation that may have been read in as words) from the resume set.\n",
    "\n",
    "Lastly, a comment line (text string) and the new set are displayed on the terminal.  '\\n menas a new line will be started to write the text tring .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WORDS BEFORE MOVING PUNCTUATION\n",
      "{'hadoop,', 'web', 'modeling', 'performing', 'the', 'education', 'using', 'machine', 'bootstrap,', 'intelligence', 'hadoop', 'basic', 'cloud', 'skills', 'statistics', 'tables', 'apps', 'vba', 'camp', 'html/css,', 'advanced', 'stein', 'git/github', 'to', 'writing', 'learning,', 'contributing', 'analytics', 'pivot', 'databases', 'mongodb', 'social', 'working', 'aws', 'microsoft', 'mining,', 'leaflet.js', 'mining', 'statistics,', 'css,', 'html,', 'boot', '##', 'in', 'excel.', 'python', 'apis.', 'api', 'n.', 'from', 'sets', 'tableau,', 'software', '#', 'interactions,', 'scripts', 'files', 'learning', 'visualization', 'business', 'front-end', 'r,', 'excel,', 'data', 'developing', 'algorithms', 'interests', 'pandas', 'creating', 'analyze', 'graduate', 'd3', '*', 'visualizations', 'tableau', 'media', 'experience', 'with', 'open-source', 'and', 'd3,', 'designing', 'forecasting', 'sql,', 'big', 'mysql', 'javascript,', 'python,', 'frank'}\n",
      "\n",
      "WORDS AFTER MOVING PUNCTUATION\n",
      "{'hadoop,', 'web', 'performing', 'modeling', 'the', 'education', 'using', 'machine', 'bootstrap,', 'intelligence', 'hadoop', 'basic', 'cloud', 'skills', 'statistics', 'tables', 'apps', 'vba', 'camp', 'html/css,', 'advanced', 'stein', 'git/github', 'writing', 'to', 'learning,', 'contributing', 'analytics', 'pivot', 'databases', 'mongodb', 'social', 'working', 'aws', 'microsoft', 'mining,', 'leaflet.js', 'mining', 'statistics,', 'css,', 'html,', 'boot', '##', 'in', 'excel.', 'python', 'apis.', 'api', 'n.', 'from', 'sets', 'tableau,', 'software', 'interactions,', 'scripts', 'files', 'learning', 'visualization', 'business', 'front-end', 'r,', 'excel,', 'data', 'developing', 'algorithms', 'interests', 'pandas', 'creating', 'analyze', 'graduate', 'd3', 'visualizations', 'tableau', 'media', 'experience', 'with', 'open-source', 'and', 'd3,', 'designing', 'forecasting', 'sql,', 'big', 'mysql', 'javascript,', 'python,', 'frank'}\n"
     ]
    }
   ],
   "source": [
    "# Create a set of unique words from the resume\n",
    "resume = set()\n",
    "\n",
    "# HINT: Single elements in a programming language are often referred to as tokens\n",
    "for token in word_list:\n",
    "    resume.add(token)\n",
    "\n",
    "print('\\nWORDS BEFORE MOVING PUNCTUATION')    \n",
    "print(resume)\n",
    "\n",
    "# Remove Punctuation that were read as whole words\n",
    "punctuation = set(string.punctuation)\n",
    "# HINT: Attributes that are in `resume` that are not in `punctuation` (difference)\n",
    "resume = resume - punctuation\n",
    "\n",
    "print('\\nWORDS AFTER MOVING PUNCTUATION')    \n",
    "print(resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below prints matches from the resume set and required_words lists and then the same for matches between the resuem and desired_skills list.\n",
    "\n",
    "Next the cell removes punctuation from the resume data by doing the following (a display of the modified list is printed to the terminal after each clean-up):\n",
    "1) searching through the resume data word by word and removing matches found in a pre-intiatlized string of punctuation sets (string.punctuation)\n",
    "\n",
    "2) searching through the resume data character by character and removing matches found in a pre-intiatlized string of punctuation sets (string.punctuation) - - this search will remove any punctuation that may be \"hidden\" within a word.\n",
    " \n",
    "3) search through the resume data word by word and remove matches found in the stop_words list.  A stop word in python is normally a commonly used word (such as “the”, “a”, “an”, “in”) that should be ignored. The list can be modify the \"stop_word list by adding words of your choice in the stopwords directory.\n",
    "\n",
    "The final word_list data will have no punctuation and no stop words in the lsit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REQUIRED SKILLS\n",
      "{'statistics', 'mysql', 'python'}\n",
      "DESIRED SKILLS\n",
      "{'modeling'}\n",
      "\n",
      "WORD LIST AFTER PUNCTUATION REMOVAL\n",
      "['frank', 'n.', 'stein', '##', 'education', 'data', 'analytics', 'and', 'visualization', 'boot', 'camp', 'graduate', '##', 'experience', 'creating', 'pivot', 'tables', 'and', 'vba', 'scripts', 'in', 'excel.', 'modeling', 'and', 'forecasting', 'data', 'using', 'basic', 'statistics', 'writing', 'python', 'scripts', 'to', 'analyze', 'data', 'sets', 'from', 'files', 'and', 'apis.', 'social', 'media', 'mining', 'using', 'python', 'working', 'with', 'mysql', 'and', 'mongodb', 'databases', 'developing', 'front-end', 'web', 'visualizations', 'using', 'html,', 'css,', 'bootstrap,', 'd3,', 'and', 'leaflet.js', 'using', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'with', 'hadoop', 'working', 'with', 'machine', 'learning', 'algorithms', '##', 'skills', 'microsoft', 'excel,', 'python,', 'javascript,', 'html/css,', 'api', 'interactions,', 'social', 'media', 'mining,', 'sql,', 'hadoop,', 'tableau,', 'advanced', 'statistics,', 'machine', 'learning,', 'r,', 'git/github', '##', 'interests', 'contributing', 'to', 'open-source', 'software', 'data', 'analytics', 'with', 'python', 'and', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'with', 'html,', 'css,', 'javascript,', 'and', 'd3', 'working', 'with', 'big', 'data', 'in', 'the', 'cloud', 'using', 'aws']\n",
      "\n",
      "WORD LIST AFTER CHARACTER PUNCTUATION REMOVAL\n",
      "['frank', 'n', 'stein', '', 'education', 'data', 'analytics', 'and', 'visualization', 'boot', 'camp', 'graduate', '', 'experience', 'creating', 'pivot', 'tables', 'and', 'vba', 'scripts', 'in', 'excel', 'modeling', 'and', 'forecasting', 'data', 'using', 'basic', 'statistics', 'writing', 'python', 'scripts', 'to', 'analyze', 'data', 'sets', 'from', 'files', 'and', 'apis', 'social', 'media', 'mining', 'using', 'python', 'working', 'with', 'mysql', 'and', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'using', 'html', 'css', 'bootstrap', 'd3', 'and', 'leafletjs', 'using', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'with', 'hadoop', 'working', 'with', 'machine', 'learning', 'algorithms', '', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', '', 'interests', 'contributing', 'to', 'opensource', 'software', 'data', 'analytics', 'with', 'python', 'and', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'with', 'html', 'css', 'javascript', 'and', 'd3', 'working', 'with', 'big', 'data', 'in', 'the', 'cloud', 'using', 'aws']\n",
      "\n",
      "WORD LIST AFTER STOP WORDS\n",
      "['frank', 'n', 'stein', '', 'education', 'data', 'analytics', 'visualization', 'boot', 'camp', 'graduate', '', 'experience', 'creating', 'pivot', 'tables', 'vba', 'scripts', 'excel', 'modeling', 'forecasting', 'data', 'basic', 'statistics', 'writing', 'python', 'scripts', 'analyze', 'data', 'sets', 'from', 'files', 'apis', 'social', 'media', 'mining', 'python', 'mysql', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'html', 'css', 'bootstrap', 'd3', 'leafletjs', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'hadoop', 'machine', 'learning', 'algorithms', '', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', '', 'interests', 'contributing', 'opensource', 'software', 'data', 'analytics', 'python', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'html', 'css', 'javascript', 'd3', 'big', 'data', 'the', 'cloud', 'aws']\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Required Skills Match using Set Intersection\n",
    "print('REQUIRED SKILLS')\n",
    "print(resume & REQUIRED_SKILLS)\n",
    "\n",
    "# Calculate the Desired Skills Match using Set Intersection\n",
    "print('DESIRED SKILLS')\n",
    "print(resume & DESIRED_SKILLS)\n",
    "\n",
    "\n",
    "# Word Punctuation Cleaning\n",
    "word_list = [word for word in word_list if word not in string.punctuation]\n",
    "print('\\nWORD LIST AFTER PUNCTUATION REMOVAL')\n",
    "print(word_list)\n",
    "\n",
    "# Character Punctuation Cleaning\n",
    "word_list = [''.join(char for char in word if char not in string.punctuation) for word in word_list]\n",
    "print('\\nWORD LIST AFTER CHARACTER PUNCTUATION REMOVAL')\n",
    "print(word_list)\n",
    "\n",
    "# Clean Stop Words\n",
    "stop_words = [\"and\", \"with\", \"using\", \"##\", \"working\", \"in\", \"to\"]\n",
    "word_list = [word for word in word_list if word not in stop_words]\n",
    "print('\\nWORD LIST AFTER STOP WORDS')\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell creates a new dictionary fromt the words in the word_list using the  fromkeys() method  which returns a new dictionary with the given sequence of elements as the keys of the dictionary.\n",
    "\n",
    "Then counts the number of occurence of each word by looping through the word list and incrementing the count for matches in the key value. \n",
    "\n",
    "The Counter in python is a container that keeps track of how many times equivalent values are added in a list.  The counter is used agains the word list to match the list counter with the incremented count calcuated by looping through the list to ensure the last word was counted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'data': 7, '': 4, 'python': 4, 'analytics': 3, 'visualization': 2, 'scripts': 2, 'excel': 2, 'statistics': 2, 'social': 2, 'media': 2, 'mining': 2, 'web': 2, 'html': 2, 'css': 2, 'd3': 2, 'the': 2, 'tableau': 2, 'software': 2, 'big': 2, 'hadoop': 2, 'machine': 2, 'learning': 2, 'javascript': 2, 'frank': 1, 'n': 1, 'stein': 1, 'education': 1, 'boot': 1, 'camp': 1, 'graduate': 1, 'experience': 1, 'creating': 1, 'pivot': 1, 'tables': 1, 'vba': 1, 'modeling': 1, 'forecasting': 1, 'basic': 1, 'writing': 1, 'analyze': 1, 'sets': 1, 'from': 1, 'files': 1, 'apis': 1, 'mysql': 1, 'mongodb': 1, 'databases': 1, 'developing': 1, 'frontend': 1, 'visualizations': 1, 'bootstrap': 1, 'leafletjs': 1, 'business': 1, 'intelligence': 1, 'performing': 1, 'algorithms': 1, 'skills': 1, 'microsoft': 1, 'htmlcss': 1, 'api': 1, 'interactions': 1, 'sql': 1, 'advanced': 1, 'r': 1, 'gitgithub': 1, 'interests': 1, 'contributing': 1, 'opensource': 1, 'pandas': 1, 'designing': 1, 'apps': 1, 'cloud': 1, 'aws': 1})\n"
     ]
    }
   ],
   "source": [
    "# Resume Word Count\n",
    "# ==========================\n",
    "# Initialize a dictionary with default values equal to zero\n",
    "word_count = {}.fromkeys(word_list, 0)\n",
    "\n",
    "# Loop through the word list and count each word.\n",
    "for word in word_list:\n",
    "    word_count[word] += 1\n",
    "# print(word_count)\n",
    "\n",
    "# Bonus using collections.Counter\n",
    "word_counter = Counter(word_list)\n",
    "print(word_counter)\n",
    "\n",
    "# Comparing both word count solutions\n",
    "print(word_count == word_counter)\n",
    "\n",
    "# Top 10 Words\n",
    "print(\"Top 10 Words\")\n",
    "print(\"=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell reads through the word count dictionary and sorts the list by the word_count (key vaues) in descending order (reverse = True) and returns the first 10 keys (key lables) from the sort. (the [:10] returns the first 10 items)\n",
    "\n",
    "\n",
    "As a bonus, explain how you would get rid of the blank token:  to get rid of empty key strings you could ...\n",
    "create a new dictionary that filters out empty strings at the start of the cell and then reference the new dictionary perform sort.\n",
    "\n",
    "example:\n",
    "newdict = {k: v for k, v in word_count.items() if v is not None}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: data                 Count: 7\n",
      "Token:                      Count: 4\n",
      "Token: python               Count: 4\n",
      "Token: analytics            Count: 3\n",
      "Token: visualization        Count: 2\n",
      "Token: scripts              Count: 2\n",
      "Token: excel                Count: 2\n",
      "Token: statistics           Count: 2\n",
      "Token: social               Count: 2\n",
      "Token: media                Count: 2\n"
     ]
    }
   ],
   "source": [
    "# Sort words by count and print the top 10\n",
    "sorted_words = []\n",
    "for word in sorted(word_count, key=word_count.get, reverse=True)[:10]:\n",
    "    print(f\"Token: {word:20} Count: {word_count[word]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
